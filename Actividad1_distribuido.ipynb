{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeGuevara/Actividad1/blob/master/Actividad1_distribuido.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y1vVdJ3Ts5G",
        "outputId": "a7644e98-68c4-4293-95a4-17bb63742527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputfile = open('/content/drive/MyDrive/paginas.txt',\"r\")\n",
        "text = inputfile.read()"
      ],
      "metadata": {
        "id": "3GdoA6sRSROx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Extraer texto de la web***"
      ],
      "metadata": {
        "id": "-l3xxKEuTtwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests   # Importa la librería requests para realizar solicitudes HTTP\n",
        "from bs4 import BeautifulSoup   # Importa la clase BeautifulSoup de la librería BeautifulSoup para analizar el HTML\n",
        "\n",
        "def extract_text_from_web_pages(text):\n",
        "    urls = text.split()   # Divide el texto de entrada en URLs separadas\n",
        "    extracted_text = \"\"   # Inicializa una cadena vacía para almacenar el texto extraído de las páginas web\n",
        "\n",
        "    for url in urls:   # Itera sobre cada URL en la lista de URLs\n",
        "        response = requests.get(url)   # Realiza una solicitud HTTP GET a la URL\n",
        "        if response.status_code == 200:   # Verifica si la solicitud fue exitosa (código de estado 200)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')   # Crea un objeto BeautifulSoup para analizar el contenido HTML de la página\n",
        "            text = ' '.join([p.get_text() for p in soup.find_all('p')])   # Extrae el texto de todos los elementos de párrafo ('p') en la página\n",
        "            extracted_text += text + \"\\n\"   # Agrega el texto extraído a la cadena de texto final con un salto de línea\n",
        "\n",
        "    return extracted_text   # Devuelve el texto extraído de todas las páginas web"
      ],
      "metadata": {
        "id": "0-HjwTHQR2Qs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuzbj8nARcZW"
      },
      "source": [
        "***Data Cleaning Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-0fbUUxir"
      },
      "source": [
        "def data_clean(text):\n",
        "  NoNumbers = ''.join([i for i in text if not i.isdigit()]) #Eliminando números\n",
        "  NoNumbers = text.lower()                                  #Hacer el texto en minúsculas\n",
        "  import re\n",
        "  onlyText = re.sub(r\"[^a-z\\s]+\",' ',NoNumbers)             #Eliminando puntuación\n",
        "  finaltext = \"\".join([s for s in onlyText.strip().splitlines(True) if s.strip()]) #Eliminando las líneas nulas\n",
        "  return finaltext"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaZEltG-RY8e"
      },
      "source": [
        "***Division (Split) Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snUKGq4bsaGY"
      },
      "source": [
        "def splitlines(text, a):\n",
        "    linessplit = text.splitlines()   # Divide el texto en líneas y lo almacena en una lista\n",
        "    split1 = linessplit[0:a]   # Crea la primera división con las primeras \"a\" líneas en la división 1\n",
        "    split2 = linessplit[a:]   # Crea la segunda división con las líneas restantes a partir de la línea \"a\" en la división 2\n",
        "    return split1, split2   # Devuelve las dos divisiones como tuplas"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCdqzbevRWQn"
      },
      "source": [
        "**Función de asignador (Mapper)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnU8GzU5B1xd"
      },
      "source": [
        "def mapper(text, out_queue):\n",
        "    keyval = []   # Inicializa una lista para almacenar pares clave-valor resultantes del mapeo\n",
        "\n",
        "    # Itera sobre cada línea de texto recibida como entrada\n",
        "    for i in text:\n",
        "        wordssplit = i.split()   # Divide la línea en palabras individuales\n",
        "        for j in wordssplit:\n",
        "            keyval.append([j, 1])   # Agrega cada palabra de la línea con el valor 1 en el formato [\"word\", 1] a la lista de pares clave-valor\n",
        "\n",
        "    out_queue.put(keyval)   # Coloca la lista de pares clave-valor en la cola de salida especificada"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXjUUGQeRNwI"
      },
      "source": [
        "***Función de clasificación***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n2YBEd3LQWV"
      },
      "source": [
        "def sortedlists(list1, list2):\n",
        "    out = list1 + list2   # Concatena las dos listas de entrada en una sola lista\n",
        "\n",
        "    out.sort(key=lambda x: x[0]) # Ordena la lista combinada basándose en el primer elemento de cada sublista, que es la \"palabra\"\n",
        "\n",
        "\n",
        "    return out   # Devuelve la lista combinada y ordenadadef sortedlists(list1, list2):\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyrRnswARKwa"
      },
      "source": [
        "***Partición Funsión***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKJD5S4NQ8Sz"
      },
      "source": [
        "def partition(sorted_list):\n",
        "    sort1out = []   # Inicializa una lista para almacenar palabras que comienzan con 'a-m'\n",
        "    sort2out = []   # Inicializa una lista para almacenar palabras que comienzan con 'n-z'\n",
        "\n",
        "    # Itera sobre cada elemento de la lista de palabras ordenadas\n",
        "    for i in sorted_list:\n",
        "        if i[0][0] < 'n':   # Comprueba si la primera letra de la palabra está antes de 'n' en el orden alfabético\n",
        "            sort1out.append(i)   # Agrega la palabra a la lista sort1out si comienza con 'a-m'\n",
        "        else:\n",
        "            sort2out.append(i)   # Agrega la palabra a la lista sort2out si comienza con 'n-z'\n",
        "\n",
        "    return sort1out, sort2out   # Devuelve dos listas separadas, una con palabras de 'a-m' y otra con palabras de 'n-z'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZO9W2qfaXqp"
      },
      "source": [
        "***Reducer Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7tp4nZzci0x"
      },
      "source": [
        "def reducer(part_out1, out_queue):\n",
        "    sum_reduced = []   # Inicializa una lista para almacenar las palabras reducidas con su recuento\n",
        "\n",
        "    count = 1   # Inicializa el contador de palabras a 1\n",
        "\n",
        "    for i in range(0, len(part_out1)):\n",
        "        if i < len(part_out1) - 1:\n",
        "            if part_out1[i] == part_out1[i + 1]:\n",
        "                count = count + 1   # Incrementa el contador si la palabra actual es igual a la siguiente palabra\n",
        "            else:\n",
        "                sum_reduced.append([part_out1[i][0], count])   # Agrega la palabra junto con su recuento a la lista sum_reduced en el formato [\"palabra\", recuento]\n",
        "                count = 1   # Restablece el contador a 1\n",
        "        else:\n",
        "            sum_reduced.append(part_out1[i])   # Agrega la última palabra a la lista de salida\n",
        "\n",
        "    out_queue.put(sum_reduced)   # Coloca la lista de palabras reducidas y sus recuentos en la cola de salida"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0A44ob5kPr3"
      },
      "source": [
        "***función Multi - Threading :***\n",
        "la función definida por el usuario a continuación toma una función y dos entradas como argumentos. La función se aplica en ambas entradas simultáneamente y la función devuelve la salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFa7vWNLkOp8"
      },
      "source": [
        "import threading   # Importa la biblioteca threading para la programación multihilo\n",
        "import queue   # Importa la clase Queue de la biblioteca queue para la comunicación entre subprocesos\n",
        "\n",
        "def multi_thread_function(func, map1_input, map2_input):\n",
        "    my_queue1 = queue.Queue()   # Crea una cola para almacenar los valores de salida del mapeador 1\n",
        "    my_queue2 = queue.Queue()   # Crea una cola para almacenar los valores de salida del mapeador 2\n",
        "\n",
        "    # Crea dos subprocesos que ejecutarán la función 'func' con las entradas 'map1_input' y 'map2_input'\n",
        "    t1 = threading.Thread(target=func, args=(map1_input, my_queue1))\n",
        "    t2 = threading.Thread(target=func, args=(map2_input, my_queue2))\n",
        "\n",
        "    t1.start()   # Inicia la ejecución del hilo 1\n",
        "    t2.start()   # Inicia la ejecución del hilo 2 para ejecutarse simultáneamente con el hilo 1\n",
        "\n",
        "    t1.join()   # Espera a que el hilo 1 se ejecute por completo\n",
        "    t2.join()   # Espera a que el hilo 2 se ejecute por completo\n",
        "\n",
        "    list1out = my_queue1.get()   # Obtiene los valores de la cola del hilo 1 en una variable\n",
        "    list2out = my_queue2.get()   # Obtiene los valores de la cola del hilo 2 en una variable\n",
        "\n",
        "    return list1out, list2out   # Devuelve los valores obtenidos de los hilos 1 y 2"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PwRZCdoxW8w"
      },
      "source": [
        "***Función Main***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_UyNeIsTMI"
      },
      "source": [
        "def main_function(text):\n",
        "  textweb = extract_text_from_web_pages(text)\n",
        "  cleantext = data_clean(textweb)\n",
        "  linessplit = splitlines(cleantext,5000)\n",
        "  mapperout = multi_thread_function(mapper,linessplit[0],linessplit[1])\n",
        "  sortedwords = sortedlists(mapperout[0],mapperout[1])\n",
        "  slicedwords = partition(sortedwords)\n",
        "  reducerout = multi_thread_function(reducer,slicedwords[0],slicedwords[1])\n",
        "  return reducerout[0]+reducerout[1]\n",
        "\n",
        "output = main_function(text)\n",
        "import pandas as pd\n",
        "pd.DataFrame(output).to_csv(\"Output.csv\",index=False,header = [\"Word\",\"Frequency\"]) #Saving file as a .csv file in the current directory"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}